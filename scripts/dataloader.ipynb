{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from dataloader import load_agent_files, analyze_agents\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/u/almurph/censusdata/AgentTorch_SyntheticPopulation/scripts'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32787 parquet files\n",
      "Processing batch 1/33 (0 to 1000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 2/33 (1000 to 2000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 3/33 (2000 to 3000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 4/33 (3000 to 4000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 5/33 (4000 to 5000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 6/33 (5000 to 6000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 7/33 (6000 to 7000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 8/33 (7000 to 8000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 9/33 (8000 to 9000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 10/33 (9000 to 10000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 11/33 (10000 to 11000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 12/33 (11000 to 12000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 13/33 (12000 to 13000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 14/33 (13000 to 14000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 15/33 (14000 to 15000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 16/33 (15000 to 16000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 17/33 (16000 to 17000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 18/33 (17000 to 18000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 19/33 (18000 to 19000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 20/33 (19000 to 20000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 21/33 (20000 to 21000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 22/33 (21000 to 22000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 23/33 (22000 to 23000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 24/33 (23000 to 24000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 25/33 (24000 to 25000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 26/33 (25000 to 26000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 27/33 (26000 to 27000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 28/33 (27000 to 28000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 29/33 (28000 to 29000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 30/33 (29000 to 30000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 31/33 (30000 to 31000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 32/33 (31000 to 32000)\n",
      "Concatenating intermediate results...\n",
      "Processing batch 33/33 (32000 to 32787)\n",
      "Concatenating intermediate results...\n",
      "Concatenating final results...\n",
      "Loaded 330098383 total agents\n",
      "Total processing time: 513.94 seconds (8.57 minutes)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "df = load_agent_files(\"/u/almurph/censusdata/AgentTorch_SyntheticPopulation/output_v2/population\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"Total processing time: {total_time:.2f} seconds ({total_time/60:.2f} minutes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "export(hdf5) [########################################] 100.00% elapsed time  :  1906.06s =  31.8m =  0.5h .2h     \n",
      " "
     ]
    }
   ],
   "source": [
    "df.export(\"/u/almurph/censusdata/AgentTorch_SyntheticPopulation/output_v2/data.hdf5\", progress=True)\n",
    "\n",
    "# analyze_agents(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.68 GB\n"
     ]
    }
   ],
   "source": [
    "size_gb = os.path.getsize(\"/u/almurph/censusdata/AgentTorch_SyntheticPopulation/output_v2/data.hdf5\") / (1024 * 1024 * 1024)\n",
    "print(f\"{size_gb:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
